{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Your First ML Exploration\n",
    "## Predicting Student Performance\n",
    "\n",
    "**Due:** 1/23/2026\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Gain hands-on experience with Python data analysis libraries\n",
    "- Explore and visualize a real dataset\n",
    "- Build and evaluate linear regression models\n",
    "- Practice interpreting model performance\n",
    "- Begin thinking about model design decisions\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You work for a university that wants to predict student final exam scores based on study habits and academic history. You have data on students' **study time**, **previous exam scores**, and **attendance**, and you need to build a predictive model.\n",
    "\n",
    "Your goal: Build a model that can predict a student's final exam score so advisors can identify at-risk students early in the semester.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "The dataset `student_performance.csv` contains 50 student records with the following columns:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `student_id` | Unique student identifier |\n",
    "| `study_hours` | Average hours studied per week |\n",
    "| `previous_score` | Score on the midterm exam (0-100) |\n",
    "| `attendance` | Percentage of classes attended |\n",
    "| `final_score` | Final exam score (0-100) — **this is what we're predicting!** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 0: Setup\n",
    "\n",
    "Run the cell below to import the libraries we'll need. If you get an error, you may need to install the library (ask me or check the course discussion board for general tech questions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Make plots look nice\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Exploration (8 points)\n",
    "\n",
    "Before building any model, we need to understand our data. This is a **critical** step that many beginners skip!\n",
    "\n",
    "### 1.1 Load the Data\n",
    "\n",
    "Use `pd.read_csv()` to load the dataset into a DataFrame called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the CSV file into a DataFrame called 'data'\n",
    "# Hint: data = pd.read_csv('filename.csv')\n",
    "\n",
    "data = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 First Look at the Data\n",
    "\n",
    "Use `.head()` to see the first few rows and `.info()` to see the data types and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the first 5 rows of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display info about the DataFrame (data types, missing values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Summary Statistics\n",
    "\n",
    "Use `.describe()` to get summary statistics for all numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display summary statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualize Relationships\n",
    "\n",
    "Create scatter plots to see how each feature relates to `final_score`. I've started the first one for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 3 subplots side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: study_hours vs final_score\n",
    "axes[0].scatter(data['study_hours'], data['final_score'], alpha=0.6)\n",
    "axes[0].set_xlabel('Study Hours')\n",
    "axes[0].set_ylabel('Final Score')\n",
    "axes[0].set_title('Study Hours vs Final Score')\n",
    "\n",
    "# TODO: Plot 2: previous_score vs final_score\n",
    "# axes[1].scatter(...)\n",
    "\n",
    "\n",
    "# TODO: Plot 3: attendance vs final_score\n",
    "# axes[2].scatter(...)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 1.1\n",
    "\n",
    "Based on your exploration, which feature do you think will be the **best** predictor of final score? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *(Double-click to edit this cell)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 1.2\n",
    "\n",
    "Do you notice any missing values or obvious outliers in the data? How might these affect a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building Your First Model (8 points)\n",
    "\n",
    "Let's start with a simple **linear regression** model using just one feature: `study_hours`.\n",
    "\n",
    "### The Linear Regression Equation\n",
    "\n",
    "Linear regression finds the line of best fit:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "Where:\n",
    "- $\\hat{y}$ is the predicted final score\n",
    "- $x$ is the input feature (study hours)\n",
    "- $\\beta_0$ is the intercept (the predicted score when study_hours = 0)\n",
    "- $\\beta_1$ is the slope (how much the score changes for each additional hour of study)\n",
    "\n",
    "### 2.1 Prepare the Data\n",
    "\n",
    "We need to separate our **features** (inputs) from our **target** (what we're predicting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our feature (input) - note the double brackets to keep it as a DataFrame\n",
    "X = data[['study_hours']]\n",
    "\n",
    "# y is our target (what we're predicting)\n",
    "y = data['final_score']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create and Train the Model\n",
    "\n",
    "Now we'll create a `LinearRegression` object and \"fit\" it to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a LinearRegression model and fit it to the data\n",
    "# Hint: model = LinearRegression()\n",
    "#       model.fit(X, y)\n",
    "\n",
    "model = # YOUR CODE HERE\n",
    "\n",
    "# Fit the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Examine the Model\n",
    "\n",
    "Let's look at the coefficients our model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model parameters\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_[0]\n",
    "\n",
    "print(f\"Intercept (β₀): {intercept:.2f}\")\n",
    "print(f\"Slope (β₁): {slope:.2f}\")\n",
    "print(f\"\\nOur model equation: final_score = {intercept:.2f} + {slope:.2f} × study_hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize the Model\n",
    "\n",
    "Let's plot our regression line on top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scatter plot of the data and add the regression line\n",
    "# Hint: Use model.predict(X) to get the predicted values for the line\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of actual data\n",
    "plt.scatter(data['study_hours'], data['final_score'], alpha=0.6, label='Actual Data')\n",
    "\n",
    "# TODO: Add the regression line\n",
    "# plt.plot(data['study_hours'], model.predict(X), color='red', label='Regression Line')\n",
    "\n",
    "\n",
    "plt.xlabel('Study Hours')\n",
    "plt.ylabel('Final Score')\n",
    "plt.title('Linear Regression: Study Hours vs Final Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 2.1\n",
    "\n",
    "Interpret the slope coefficient. In plain English, what does this number tell us about the relationship between study hours and final score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 2.2\n",
    "\n",
    "The intercept represents the predicted score when study_hours = 0. Does this value make practical sense? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Evaluating Your Model (8 points)\n",
    "\n",
    "How do we know if our model is any good? We need **metrics** to measure performance.\n",
    "\n",
    "### Common Regression Metrics\n",
    "\n",
    "- **MAE (Mean Absolute Error):** Average absolute difference between predicted and actual values\n",
    "- **MSE (Mean Squared Error):** Average squared difference (penalizes large errors more)\n",
    "- **RMSE (Root Mean Squared Error):** Square root of MSE (same units as the target)\n",
    "\n",
    "### 3.1 Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all data points\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Look at the first few predictions vs actual values\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y.head(10).values,\n",
    "    'Predicted': y_pred[:10].round(2),\n",
    "    'Error': (y.head(10).values - y_pred[:10]).round(2)\n",
    "})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculate Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate MAE, MSE, and RMSE\n",
    "# Hint: Use mean_absolute_error(y, y_pred) and mean_squared_error(y, y_pred)\n",
    "#       RMSE is just np.sqrt(MSE)\n",
    "\n",
    "mae = # YOUR CODE HERE\n",
    "mse = # YOUR CODE HERE\n",
    "rmse = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize the Errors\n",
    "\n",
    "Let's create a plot showing the prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of the errors (y - y_pred)\n",
    "# Hint: plt.hist(y - y_pred, bins=15)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Zero Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 3.1\n",
    "\n",
    "What does an MAE of your calculated value mean in practical terms? Is this acceptable for predicting exam scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 3.2\n",
    "\n",
    "Look at the error histogram. Is it roughly centered around zero? What would it mean if the errors were mostly positive or mostly negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Train/Test Split (8 points)\n",
    "\n",
    "**Important concept:** We've been evaluating our model on the same data we used to train it. This can give us an overly optimistic view of how well our model will perform on **new, unseen data**.\n",
    "\n",
    "### The Problem with Training Error\n",
    "\n",
    "A model can \"memorize\" the training data without learning the underlying pattern. To get a realistic estimate of performance, we split our data:\n",
    "\n",
    "- **Training set:** Used to train (fit) the model\n",
    "- **Test set:** Held out and only used to evaluate the final model\n",
    "\n",
    "### 4.1 Create the Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and test sets\n",
    "# Use test_size=0.2 (20% for testing) and random_state=42 (for reproducibility)\n",
    "# Hint: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train a New Model on Training Data Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new LinearRegression model and train it on ONLY the training data\n",
    "\n",
    "model_split = # YOUR CODE HERE\n",
    "\n",
    "# Fit on training data only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluate on Both Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate MAE for both training and test sets\n",
    "# Hint: First predict, then calculate MAE\n",
    "\n",
    "# Predictions on training set\n",
    "y_train_pred = # YOUR CODE HERE\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred = # YOUR CODE HERE\n",
    "\n",
    "# Calculate MAE for each\n",
    "train_mae = # YOUR CODE HERE\n",
    "test_mae = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Training MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 4.1\n",
    "\n",
    "Compare the training MAE to the test MAE. What do you observe? Why might these be different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 4.2\n",
    "\n",
    "If the test MAE was much larger than the training MAE, what might that indicate about your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Adding More Features (10 points)\n",
    "\n",
    "We've only been using `study_hours` so far. Let's see if we can build a better model by including more features.\n",
    "\n",
    "### 5.1 Multiple Linear Regression\n",
    "\n",
    "The equation becomes:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3$$\n",
    "\n",
    "Where $x_1$ = study_hours, $x_2$ = previous_score, $x_3$ = attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create X with multiple features\n",
    "# Hint: X_multi = data[['study_hours', 'previous_score', 'attendance']]\n",
    "\n",
    "X_multi = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Features shape: {X_multi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train/Test Split with Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the multi-feature data\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train and Evaluate the Multi-Feature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create, train, and evaluate a model with multiple features\n",
    "\n",
    "model_multi = # YOUR CODE HERE\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred_multi = # YOUR CODE HERE\n",
    "\n",
    "# Calculate test MAE\n",
    "test_mae_multi = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Multi-feature Test MAE: {test_mae_multi:.2f}\")\n",
    "print(f\"Single-feature Test MAE: {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Examine the Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what the model learned\n",
    "print(f\"Intercept: {model_multi.intercept_:.4f}\")\n",
    "print(\"\\nCoefficients:\")\n",
    "for feature, coef in zip(['study_hours', 'previous_score', 'attendance'], model_multi.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 5.1\n",
    "\n",
    "Did adding more features improve the model? Compare the test MAE of the multi-feature model to the single-feature model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 5.2\n",
    "\n",
    "Look at the coefficients. Which feature has the largest impact on the prediction? Does this match your intuition from the data exploration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Making Predictions (4 points)\n",
    "\n",
    "Now let's use our model to make predictions for new students.\n",
    "\n",
    "### 6.1 Predict for New Students\n",
    "\n",
    "Suppose we have three new students:\n",
    "- **Student A:** Studies 6 hours/week, previous score 75, attendance 85%\n",
    "- **Student B:** Studies 2 hours/week, previous score 55, attendance 60%\n",
    "- **Student C:** Studies 8 hours/week, previous score 90, attendance 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a DataFrame with the new students' data and make predictions\n",
    "# Hint: new_students = pd.DataFrame({'study_hours': [6, 2, 8], ...})\n",
    "\n",
    "new_students = pd.DataFrame({\n",
    "    'study_hours': # YOUR CODE HERE,\n",
    "    'previous_score': # YOUR CODE HERE,\n",
    "    'attendance': # YOUR CODE HERE\n",
    "})\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_multi.predict(new_students)\n",
    "\n",
    "# Display results\n",
    "new_students['predicted_score'] = predictions.round(1)\n",
    "new_students['student'] = ['A', 'B', 'C']\n",
    "print(new_students[['student', 'study_hours', 'previous_score', 'attendance', 'predicted_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 6.1\n",
    "\n",
    "Which student(s) might need academic intervention based on your predictions? What threshold would you use to identify \"at-risk\" students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Reflection (4 points)\n",
    "\n",
    "Take a step back and think critically about what you've built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 7.1\n",
    "\n",
    "What are some limitations of this model, i.e., what sort of behavior could be missed? What factors that might affect student performance are NOT included in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 7.2\n",
    "\n",
    "If you were deploying this model in a real university setting, what ethical considerations should you think about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ Question 7.3\n",
    "\n",
    "On a scale of 1-10, how confident are you in this model's predictions? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Instructions\n",
    "\n",
    "Submit TWO files to Canvas:\n",
    "\n",
    "1. **Your Jupyter Notebook** (`.ipynb` file)\n",
    "   - Must include all code cells run (with outputs visible)\n",
    "   - Must include all your answers to questions in markdown cells\n",
    "   - Must be clearly organized with section headers\n",
    "\n",
    "2. **A PDF export** of your notebook (File → Download → PDF)\n",
    "   - Backup in case notebook doesn't load properly\n",
    "\n",
    "**File naming:** `Assignment1_LastName_FirstName.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "## Optional Challenge\n",
    "\n",
    "Try one or more of these extensions:\n",
    "\n",
    "1. **Create a new feature:** Build a feature that combines existing features (e.g., `study_hours × attendance`). Does it improve your model?\n",
    "\n",
    "2. **Find the worst prediction:** Identify the student where your model was most wrong. Can you explain why?\n",
    "\n",
    "3. **Different train/test splits:** Try different split ratios (50/50, 90/10). How does it affect performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
